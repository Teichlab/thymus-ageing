{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thymus Ageing Atlas: Load velocyto outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import session_info\n",
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import hdf5plugin\n",
    "\n",
    "# Add repo path to sys path (allows to access scripts and metadata from repo)\n",
    "#repo_path,_ = os.path.split(os.path.split(os.getcwd())[0])\n",
    "repo_path = '/lustre/scratch126/cellgen/team205/lm25/thymus_projects/thymus_ageing_atlas/General_analysis'\n",
    "sys.path.insert(1, repo_path) \n",
    "sys.path.insert(2, '/lustre/scratch126/cellgen/team205/lm25/thymus_projects/thymus_ageing_atlas/General_analysis/scripts')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Define paths\n",
    "plots_path = f'{repo_path}/plots/preprocessing'\n",
    "data_path = f'{repo_path}/data'\n",
    "general_data_path = f'{repo_path}/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update metadata\n",
    "from utils import get_latest_version,update_obs\n",
    "\n",
    "latest_meta_path = get_latest_version(dir = f'{general_data_path}/metadata', file_prefix='Thymus_ageing_metadata')\n",
    "meta = pd.read_excel(latest_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Load adata\n",
    "object_version = 'v4_2025-02-04'\n",
    "adata = ad.read_h5ad(f'{general_data_path}/objects/rna/thyAgeing_all_scvi_{object_version}.zarr')\n",
    "\n",
    "# Add new annotations to adata\n",
    "ct_anno = pd.read_csv(f'{general_data_path}/objects/rna/thyAgeing_all_scvi_{object_version}_curatedAnno_v8.csv', index_col = 0)\n",
    "for c in ct_anno.columns:\n",
    "    if c in adata.obs.columns:\n",
    "        adata.obs.drop(c, axis = 1, inplace = True)\n",
    "adata.obs = adata.obs.join(ct_anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary with paths to velocyto data\n",
    "velocyto_meta = meta.loc[(meta['chemistry_simple'] == '5GEX') & (~pd.isna(meta['path_raw_gex'])) & (meta['health_status'] == 'healthy')]\n",
    "demux_libs = velocyto_meta.loc[(velocyto_meta['library'].str.count('_') ==2) & (velocyto_meta['study'] == 'Notarangelo2024')]\n",
    "velocyto_meta = velocyto_meta.loc[~velocyto_meta['library'].isin(demux_libs['library'])]\n",
    "\n",
    "velocyto_meta['study'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocyto_meta['path_raw_gex'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_wo_gex = []\n",
    "missing_mat = []\n",
    "for sample,gex_path in zip(velocyto_meta['library'],velocyto_meta['path_raw_gex']):\n",
    "    velo_path = gex_path.replace('Gene','Velocyto/raw')\n",
    "    if os.path.exists(velo_path):\n",
    "        if not os.path.exists(f'{velo_path}/spliced.mtx') and not os.path.exists(f'{velo_path}/spliced.mtx.gz'):\n",
    "            print(f'{sample} does not have spliced.mtx')\n",
    "            missing_mat.append(sample)\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        print(f'{sample} does not exist')\n",
    "        samples_wo_gex.append(sample)\n",
    "        \n",
    "# Could not find that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove samples without gex data\n",
    "velocyto_meta = velocyto_meta.loc[~velocyto_meta['library'].isin(samples_wo_gex)]\n",
    "velocyto_meta.shape\n",
    "\n",
    "# Write to file\n",
    "velocyto_meta.to_csv(f'{data_path}/objects/velocyto/thyAgeing_all_scvi_{object_version}_velocyto_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_dir = f'{data_path}/objects/velocyto/compartment_barcodes'\n",
    "for c in adata.obs['taa_l1'].unique():\n",
    "    barcodes = adata.obs_names[adata.obs['taa_l1'] == c].tolist()\n",
    "    barcodes = pd.Series(barcodes)\n",
    "    barcodes.to_csv(f'{barcode_dir}/thyAgeing_all_scvi_{object_version}_{c}_barcodes.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test snippet\n",
    "# sys.path.insert(1, f'{repo_path}/scripts')\n",
    "# from utils import velocyto_to_anndata\n",
    "\n",
    "# barcodes_path = '/lustre/scratch126/cellgen/team205/lm25/thymus_projects/thymus_ageing_atlas/General_analysis/data/objects/velocyto/compartment_barcodes/thyAgeing_all_scvi_v4_2025-02-04_B_barcodes.tsv'\n",
    "# meta_path = '/lustre/scratch126/cellgen/team205/lm25/thymus_projects/thymus_ageing_atlas/General_analysis/data/objects/velocyto/thyAgeing_all_scvi_v4_2025-02-04_velocyto_meta.csv'\n",
    "\n",
    "# # Read barcodes and meta\n",
    "# meta = pd.read_csv(meta_path, index_col = 0)\n",
    "# barcodes = pd.read_csv(barcodes_path, sep='\\t', header=None)[0].tolist()\n",
    "\n",
    "# velocyto_adata = velocyto_to_anndata(meta = velocyto_meta.iloc[:8], subset_barcodes=barcodes, n_cpu = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define columns\n",
    "cell_types = adata.obs['taa_l1'].unique()\n",
    "velocyto_dir = f'{data_path}/objects/velocyto'\n",
    "meta_path = f'{velocyto_dir}/thyAgeing_all_scvi_v4_2025-02-04_velocyto_meta.csv'\n",
    "n_cpu = 4\n",
    "\n",
    "for ct in cell_types[1:]:\n",
    "    barcodes_path = f'{velocyto_dir}/compartment_barcodes/thyAgeing_all_scvi_v4_2025-02-04_{ct}_barcodes.tsv'\n",
    "    out_name = f'{velocyto_dir}/thyAgeing_all_scvi_v4_2025-02-04_{ct}_velocyto.zarr'\n",
    "    \n",
    "    # Create the command to run the Python function\n",
    "    command = (\n",
    "        f'source /nfs/users/nfs_l/lm25/.bashrc ; conda activate /nfs/team205/lm25/condaEnvs/thymusAgeing ;'\n",
    "        f'python {repo_path}/notebooks/preprocessing/01b_dataIntegration_velocyto.py'\n",
    "        f' --barcodes_path {barcodes_path}'\n",
    "        f' --velocyto_meta_path {meta_path}'\n",
    "        f' --out_file_name {out_name}'\n",
    "        f' --n_cpu {n_cpu}'\n",
    "    )\n",
    "\n",
    "    # Submit the command as an LSF job\n",
    "    subprocess.run([\n",
    "        'bsub',\n",
    "        '-q', 'hugemem',\n",
    "        '-G', 'team361',\n",
    "        '-J', f'velocyto_{ct}',\n",
    "        '-o', f'{velocyto_dir}/logs/velocyto_{ct}_%J.out',\n",
    "        '-e', f'{velocyto_dir}/logs/velocyto_{ct}_%J.err',\n",
    "        '-n', f'{n_cpu}',\n",
    "        \"-M250000\",\n",
    "        \"-R\", \"span[hosts=1] select[mem>250000] rusage[mem=250000]\",\n",
    "        '-W', '03:00', \n",
    "        f\" eval {command}\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocyto on multiplexed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary with paths to velocyto data\n",
    "velocyto_meta_demux = meta.loc[meta['library'].isin(demux_libs['library'].tolist())]\n",
    "velocyto_meta_demux = velocyto_meta_demux.drop_duplicates(subset = 'library')\n",
    "\n",
    "velocyto_meta_demux['path_raw_gex'].isna().sum(), velocyto_meta_demux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocyto_meta_demux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# Test snippet\n",
    "sys.path.insert(1, f'{repo_path}/scripts')\n",
    "from utils import velocyto_to_anndata\n",
    "\n",
    "velocyto_adata_demux = velocyto_to_anndata(meta = velocyto_meta_demux, col_library = 'library', col_prefix = 'index', n_cpu = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove sample from obs (needs to be added through demuxing)\n",
    "velocyto_adata_demux.obs.drop(columns=['sample','index'], inplace=True)\n",
    "velocyto_adata_demux.obs['barcode'] = velocyto_adata_demux.obs_names.str.split('-').str[-1]\n",
    "\n",
    "velocyto_adata_demux.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_assignments = pd.read_csv('/lustre/scratch126/cellgen/team205/lm25/raw_data/Notarangelo2024/HTO_CITEseq_count_outputs/Notarangelo2024_HTO_barcode_assignments.csv')\n",
    "barcode_assignments = barcode_assignments.merge(velocyto_meta_demux[['index', 'library']].drop_duplicates(), on = 'index')\n",
    "\n",
    "barcode_assignments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocyto_adata_demux.obs = velocyto_adata_demux.obs.merge(barcode_assignments, on = ['barcode', 'library'], how = 'left')\n",
    "velocyto_adata_demux.obs_names = velocyto_adata_demux.obs['hto_assignment.1']\n",
    "\n",
    "velocyto_adata_demux.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter adata to only contain barcodes from samples of interest and add metadata\n",
    "velocyto_adata_demux = velocyto_adata_demux[~velocyto_adata_demux.obs['index'].isna()]\n",
    "velocyto_adata_demux.obs.drop(columns=['hto_assignment', 'hto_assignment_orig', 'hto_assignment.1'], inplace=True)\n",
    "\n",
    "velocyto_adata_demux.obs = pd.merge(left = velocyto_adata_demux.obs.reset_index(names = 'names'), right = velocyto_meta_demux, how = \"left\", on=['index', 'library']).set_index('names')\n",
    "\n",
    "velocyto_adata_demux.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocyto_adata_demux.obs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in velocyto_adata_demux.obs.columns:\n",
    "    if velocyto_adata_demux.obs[c].dtype == 'object':\n",
    "        velocyto_adata_demux.obs[c] = velocyto_adata_demux.obs[c].astype('str')\n",
    "        \n",
    "velocyto_adata_demux.write_h5ad( f'{velocyto_dir}/thyAgeing_Notarangelo2024_velocyto.zarr',\n",
    "                compression=hdf5plugin.FILTERS[\"zstd\"],\n",
    "                compression_opts=hdf5plugin.Zstd(clevel=5).filter_options,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some of the samples require correction of the format to make them readable by scanpy functions (hence this function)\n",
    "def feature_check_correct (sample, feature_path):\n",
    "    features = pd.read_csv(f\"{feature_path}/features.tsv.gz\", sep = '\\t', header = None)\n",
    "    if (features.shape[1]<3):\n",
    "        features.loc[:,2]= 'Gene Expression'\n",
    "    #   shutil.copyfile(f\"{cr_gene_filtered_mtx}/features.tsv.gz\", f\"{cr_gene_filtered_mtx}/features2.tsv.gz\")\n",
    "        features.to_csv(f\"{cr_gene_filtered_mtx}/features.tsv.gz\", header=False, index=False, sep = '\\t')\n",
    "        print(f\"{sample} features corrected\")\n",
    "### Actual reader \n",
    "def AnnData_from_files_v2(samples, starsolo_path, cellbender_path, meta):\n",
    "    #Writing output from separate samples, processed using CellRanger, into a dictionary of Scanpy objects:\n",
    "    import numpy as np\n",
    "    from scipy import sparse\n",
    "    ad = []\n",
    "    #Generate AnnData for each sample\n",
    "    for sid in samples:\n",
    "        cr_filt_path = f\"{starsolo_path}/{sid}/logs/GeneFull/filtered\"\n",
    "        cr_velo_path = f\"{starsolo_path}/{sid}/logs/Velocyto/raw\"\n",
    "        cb_filt_path = f\"{cellbender_path}/{sid}/{sid}_filtered.h5\"\n",
    "        feature_check_correct(sample = sid, feature_path=cr_filt_path)\n",
    "        feature_check_correct(sample = sid, feature_path=cr_velo_path)\n",
    "        \n",
    "        cr_gene_filtered_ad = sc.read_10x_mtx(cr_filt_path)\n",
    "        print(\"cr_gene_filtered_mtx read\")\n",
    "        cb_gene_filtered_ad = sc.read_10x_h5(cb_filt_path)\n",
    "        print(\"cb_filtered_h5 read\")\n",
    "        \n",
    "        velocyto_ad = sc.read_10x_mtx(cr_velo_path)\n",
    "        print(\"Incorrect velocyto is read\")\n",
    "        shapex = np.loadtxt(f'{cr_velo_path}/matrix.mtx', skiprows=2, max_rows = 1, delimiter=' ')[0:2].astype(int)\n",
    "        mtx = np.loadtxt(f'{cr_velo_path}/matrix.mtx', skiprows=3, delimiter=' ')\n",
    "        spliced = sc.AnnData(X = sparse.csr_matrix((mtx[:,2], (mtx[:,0]-1, mtx[:,1]-1)), shape = shapex).T, \n",
    "                             dtype = 'float32', obs = velocyto_ad.obs, var = velocyto_ad.var)\n",
    "        unspliced = sc.AnnData(X = sparse.csr_matrix((mtx[:,3], (mtx[:,0]-1, mtx[:,1]-1)), shape = shapex).T, \n",
    "                              dtype = 'float32', obs = velocyto_ad.obs, var = velocyto_ad.var)\n",
    "        ambiguous = sc.AnnData(X = sparse.csr_matrix((mtx[:,4], (mtx[:,0]-1, mtx[:,1]-1)), shape = shapex).T, \n",
    "                              dtype = 'float32', obs = velocyto_ad.obs, var = velocyto_ad.var)\n",
    "        print(\"velocyto mtx done\")\n",
    "\n",
    "        common_cells = list(\n",
    "            set(cr_gene_filtered_ad.obs_names.tolist()) & set(cb_gene_filtered_ad.obs_names.tolist()))\n",
    "        \n",
    "        ad1 = sc.AnnData(\n",
    "            X=cb_gene_filtered_ad[common_cells, :].X,\n",
    "            obs=cb_gene_filtered_ad.obs.loc[common_cells,:].copy(),\n",
    "            var=cb_gene_filtered_ad.var.copy(),\n",
    "            layers={\n",
    "                \"raw\": cr_gene_filtered_ad[common_cells, :].X,\n",
    "                \"spliced\": spliced[common_cells, :].X,\n",
    "                \"unspliced\": unspliced[common_cells, :].X,\n",
    "                \"ambiguous\": ambiguous[common_cells, :].X,\n",
    "            },\n",
    "        )\n",
    "        ad1.var.rename(columns = {'gene_ids':'ENSEMBL'}, inplace = True)\n",
    "        ad1.var['SYMBOL'] = ad1.var.index\n",
    "        ad1.var_names_make_unique() \n",
    "        ad1.obs['SampleID'] = sid\n",
    "        ad1.obs['barcode'] = ad1.obs_names\n",
    "        ad1.obs_names = ad1.obs['SampleID']+\"-\"+ad1.obs['barcode']\n",
    "        ad.append(ad1)\n",
    "        print(f\"{sid} anndata created\")\n",
    "    from anndata import AnnData\n",
    "    adata = ad[0].concatenate (ad[1:], batch_key = 'concat_sample_no', index_unique = None)\n",
    "    #Add cleaned metadata to the Anndata.obs table\n",
    "    obs_merged = pd.merge(left = adata.obs, right = meta, how = \"left\", left_on=\"SampleID\", right_on=\"SampleID\")\n",
    "    obs_merged.index = obs_merged['SampleID']+\"-\"+obs_merged['barcode']\n",
    "    adata.obs = obs_merged\n",
    "    return adata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
