{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af4f0dd",
   "metadata": {},
   "source": [
    "# Load data for final version of thymus ageing atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import session_info\n",
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import hdf5plugin\n",
    "\n",
    "# Add repo path to sys path (allows to access scripts and metadata from repo)\n",
    "#repo_path,_ = os.path.split(os.path.split(os.getcwd())[0])\n",
    "repo_path = '/lustre/scratch126/cellgen/team205/lm25/thymus_projects/thymus_ageing_atlas/General_analysis'\n",
    "sys.path.insert(1, repo_path) \n",
    "sys.path.insert(2, '/lustre/scratch126/cellgen/team205/lm25/thymus_projects/thymus_ageing_atlas/General_analysis/scripts')\n",
    "\n",
    "# Add R libs path\n",
    "#os.environ['LD_LIBRARY_PATH'] = '' # Uncomment on jhub\n",
    "#os.environ['R_HOME'] = '/nfs/team205/lm25/condaEnvs/thymusAgeing/lib/R' # Uncomment on jhub\n",
    "os.environ['R_LIBS_USER'] = '/nfs/team205/lm25/condaEnvs/thymusAgeing/lib/R/library'\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c31351",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%R\n",
    "\n",
    "library(tidyverse)\n",
    "library(patchwork)\n",
    "library(magrittr)\n",
    "\n",
    "source('/nfs/team205/lm25/customScripts/visualisation/customTheme.R')\n",
    "\n",
    "options(max.print=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "plots_path = f'{repo_path}/plots/preprocessing'\n",
    "data_path = f'{repo_path}/data'\n",
    "general_data_path = f'{repo_path}/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac5b79",
   "metadata": {},
   "source": [
    "# Inspect metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3776893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latest metadata\n",
    "from utils import get_latest_version,update_obs\n",
    "\n",
    "latest_meta_path = get_latest_version(dir = f'{general_data_path}/metadata', file_prefix='Thymus_ageing_metadata')\n",
    "latest_meta = pd.read_excel(latest_meta_path)\n",
    "\n",
    "latest_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91219183",
   "metadata": {},
   "source": [
    "## Demultiplex Notarangelo2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e74a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "notarangelo_meta = latest_meta[latest_meta['study'] == 'Notarangelo2024']\n",
    "\n",
    "notarangelo_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify libraries for demuxing\n",
    "demux_lib = notarangelo_meta[notarangelo_meta['library'].str.count('_') == 2]['library'].unique()\n",
    "\n",
    "demux_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220073d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmread\n",
    "from scipy.sparse import csr_matrix\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def import_hto_matrix(path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Imports an HTO (Hashtag Oligo) matrix from the specified directory.\n",
    "    This function reads a sparse matrix from a Matrix Market file, along with\n",
    "    corresponding features and barcodes from TSV files, and returns an AnnData\n",
    "    object containing the data.\n",
    "    Parameters:\n",
    "    path (str): The directory path where the matrix.mtx.gz, features.tsv.gz, \n",
    "                and barcodes.tsv.gz files are located.\n",
    "    Returns:\n",
    "    ad.AnnData: An AnnData object containing the imported HTO matrix with \n",
    "                barcodes as observations and features as variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the matrix file as a sparse matrix\n",
    "    sparse_matrix = mmread(f'{path}/matrix.mtx.gz').tocsr()\n",
    "    features = pd.read_csv(f'{path}features.tsv.gz', sep='\\t', header=None)[0]\n",
    "    barcodes = pd.read_csv(f'{path}/barcodes.tsv.gz', sep='\\t', header=None)[0]\n",
    "\n",
    "    adata = ad.AnnData(X=sparse_matrix.T)\n",
    "    adata.obs_names = barcodes\n",
    "    adata.var_names = features\n",
    "\n",
    "    return adata\n",
    "\n",
    "def assign_hto(adata: ad.AnnData, run_id : int, lib : List, hto_map: pd.DataFrame) -> ad.AnnData:\n",
    "    \"\"\"\n",
    "    Assigns HTO (Hashtag Oligonucleotide) labels to the AnnData object based on the provided HTO mapping.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : ad.AnnData\n",
    "        Annotated data matrix.\n",
    "    run_id : int\n",
    "        Identifier for the sequencing run.\n",
    "    lib : List\n",
    "        List of libraries to consider for HTO assignment.\n",
    "    hto_map : pd.DataFrame\n",
    "        DataFrame containing the HTO mapping information. It should have columns 'Sequencing_run_name', \n",
    "        'Library', 'Sample1', 'Sample2', 'Sample1.HTO', and 'Sample2.HTO'.\n",
    "    Returns:\n",
    "    --------\n",
    "    ad.AnnData\n",
    "        The AnnData object with updated HTO assignments in the observation (obs) metadata.\n",
    "    \"\"\"\n",
    "    \n",
    "    max_counts = np.array(adata.X.argmax(axis=1)).flatten()\n",
    "\n",
    "    adata.obs['barcode'] = adata.obs_names\n",
    "    adata.obs['hto_assignment_orig'] = [adata.var_names[i] for i in max_counts]\n",
    "\n",
    "    hto_dict = hto_map.loc[(hto_map['Sequencing_run_name'] == run_id) & (hto_map['Library'].isin(lib))][['Sample1', 'Sample2', 'Sample1.HTO', 'Sample2.HTO']].set_index('Sample1.HTO')['Sample1'].to_dict()\n",
    "    hto_dict.update(hto_map.loc[(hto_map['Sequencing_run_name'] == run_id) & (hto_map['Library'].isin(lib))][['Sample1', 'Sample2', 'Sample1.HTO', 'Sample2.HTO']].set_index('Sample2.HTO')['Sample2'].to_dict())\n",
    "\n",
    "    print(hto_dict)\n",
    "    print(adata.obs['hto_assignment_orig'].str.split('-').str[0].unique())\n",
    "    adata.obs['index'] = [hto_dict[s.split('-')[0]] if s.split('-')[0] in hto_dict.keys() else pd.NA for s in adata.obs['hto_assignment_orig']]\n",
    "    adata.obs['hto_assignment'] = [f'{i}-{b}' if not pd.isna(i) else pd.NA for i,b in zip(adata.obs['index'], adata.obs_names)]\n",
    "\n",
    "    adata.obs_names = adata.obs['hto_assignment']\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def hto_demux(path: str, hto_map: pd.DataFrame, run_id: int, lib: List) -> ad.AnnData:\n",
    "    \"\"\"\n",
    "    Demultiplexes the HTO (Hashtag Oligonucleotide) data based on the provided HTO mapping.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        Path to the HTO matrix file.\n",
    "    hto_map : pd.DataFrame\n",
    "        DataFrame containing the HTO mapping information. It should have columns 'Sequencing_run_name', \n",
    "        'Library', 'Sample1', 'Sample2', 'Sample1.HTO', and 'Sample2.HTO'.\n",
    "    run_id : int\n",
    "        Identifier for the sequencing run.\n",
    "    lib : List\n",
    "        List of libraries to consider for HTO assignment.\n",
    "    Returns:\n",
    "    --------\n",
    "    ad.AnnData\n",
    "        The AnnData object with demultiplexed HTO data.\n",
    "    \"\"\"\n",
    "    \n",
    "    adata = import_hto_matrix(path)\n",
    "    adata = assign_hto(adata, run_id, lib, hto_map)\n",
    "    \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HTO mapping info\n",
    "hto_map = pd.read_excel('/lustre/scratch126/cellgen/team205/lm25/raw_data/Notarangelo2024/Notarangelo2024_meta.xlsx', sheet_name='HTO.sample.assignments')\n",
    "hto_map['Sample1.HTO'] = hto_map['Sample1.HTO'].apply(lambda x: f'HTO_{x[-1]}')\n",
    "hto_map['Sample2.HTO'] = hto_map['Sample2.HTO'].apply(lambda x: f'HTO_{x[-1]}')\n",
    "\n",
    "hto_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61002a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = hto_map[['Sequencing_run_name', 'Library', 'HTO.name']].drop_duplicates().groupby(['Sequencing_run_name', 'HTO.name']).apply(lambda x: x['Library'].tolist()).to_frame(name='Library').reset_index()\n",
    "\n",
    "barcode_assignments = []\n",
    "# Fix: Use iterrows() to iterate over DataFrame rows\n",
    "for _, row in all_runs.iterrows():\n",
    "    run_id = row['Sequencing_run_name']\n",
    "    lib = row['Library']\n",
    "    hto_name = row['HTO.name']\n",
    "    \n",
    "    hto_path = f'/lustre/scratch126/cellgen/team205/lm25/raw_data/Notarangelo2024/HTO_CITEseq_count_outputs/{run_id}/HTO_counts_{run_id}_{hto_name}/read_count/'\n",
    "    adata = hto_demux(hto_path, hto_map, run_id, lib)\n",
    "    \n",
    "    barcode_assignments.append(adata.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9facd36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_assignments = pd.concat(barcode_assignments)\n",
    "\n",
    "barcode_assignments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d783bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_assignments['index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_assignments.to_csv(f'/lustre/scratch126/cellgen/team205/lm25/raw_data/Notarangelo2024/HTO_CITEseq_count_outputs/Notarangelo2024_HTO_barcode_assignments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69dab99",
   "metadata": {},
   "source": [
    "# Assemble cell h5ad object\n",
    "\n",
    "## Select libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd16c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_meta = latest_meta.loc[(latest_meta['health_status'] == 'healthy') & (latest_meta['type'] == 'cells') & (latest_meta['age_group'].isin(['infant', 'paed', 'adult'])) & (latest_meta['study'] != 'Notarangelo2024')]\n",
    "\n",
    "# Select specific samples for Notarangelo2024 study\n",
    "notarangelo_meta = latest_meta.loc[latest_meta['study'] == 'Notarangelo2024']\n",
    "notarangelo_samples = notarangelo_meta.loc[(notarangelo_meta['age_group'].isin(['adult', 'paed'])) & (notarangelo_meta['health_status'] == 'healthy')]['index'].tolist()\n",
    "notarangelo_samples.extend(notarangelo_meta.loc[(notarangelo_meta['age_group'].isin(['infant'])) & (notarangelo_meta['health_status'] == 'healthy') & (notarangelo_meta['age'].isin(['7d', '4m', '11m']))]['index'].tolist())  \n",
    "\n",
    "cells_meta = pd.concat([cells_meta, latest_meta.loc[latest_meta['index'].isin(notarangelo_samples)]])\n",
    "\n",
    "cells_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ea50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any library is missing cellbender paths\n",
    "any(pd.isna(cells_meta['path_cellbender_gex']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a248564",
   "metadata": {},
   "source": [
    "## Check which sorts TabSap datasets are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16d8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabsap_meta = cells_meta.loc[cells_meta['study'] == 'TabulaSapiens2022']\n",
    "tabsap_meta['sample'] = tabsap_meta['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a217848",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabsap_meta[['sample', 'sort']] # Sorts assigned by Veronika (metadata v9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8826051",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabsap_adata = cellbender_to_anndata(tabsap_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfff30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in tabsap_adata.obs['sample'].unique():\n",
    "    expr = tabsap_adata[tabsap_adata.obs['sample'] == s, 'CD3E'].X.sum(0)/tabsap_adata[tabsap_adata.obs['sample'] == s].shape[0]\n",
    "    assign = tabsap_adata[tabsap_adata.obs['sample'] == s].obs['sort'].unique()[0]\n",
    "    print(f'{s}:{expr} -> {assign}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af348d",
   "metadata": {},
   "source": [
    "NOTE: I reassigned sorts based on whether CD3E > 0 (CD3P). Strangely, that means that both 5' samples of TSP2 are CD3P..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35733f6",
   "metadata": {},
   "source": [
    "## Create object for demultiplexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc3183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import cellbender_to_anndata, add_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d460cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "demux_meta = cells_meta.loc[(cells_meta['study'] == 'Notarangelo2024') & (cells_meta['library'].str.count('_') == 2)]\n",
    "\n",
    "demux_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769db421",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "demux_adata = cellbender_to_anndata(demux_meta, col_library='library', col_prefix='library', add_meta=False)\n",
    "\n",
    "demux_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9913088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove sample from obs (needs to be added through demuxing)\n",
    "demux_adata.obs.drop(columns='sample', inplace=True)\n",
    "\n",
    "demux_adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212a1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_assignments = pd.read_csv('/lustre/scratch126/cellgen/team205/lm25/raw_data/Notarangelo2024/HTO_CITEseq_count_outputs/Notarangelo2024_HTO_barcode_assignments.csv')\n",
    "barcode_assignments = barcode_assignments.merge(demux_meta[['index', 'library']].drop_duplicates(), on = 'index')\n",
    "\n",
    "barcode_assignments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49361de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "demux_adata.obs = demux_adata.obs.merge(barcode_assignments, on = ['barcode', 'library'], how = 'left')\n",
    "demux_adata.obs_names = demux_adata.obs['index'] + '-' + demux_adata.obs['barcode']\n",
    "\n",
    "demux_adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c771bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter adata to only contain barcodes from samples of interest and add metadata\n",
    "demux_adata = demux_adata[~demux_adata.obs['index'].isna()]\n",
    "demux_adata.obs.drop(columns=['hto_assignment', 'hto_assignment_orig', 'hto_assignment.1'], inplace=True)\n",
    "\n",
    "demux_adata.obs = pd.merge(left = demux_adata.obs.reset_index(names = 'names'), right = demux_meta, how = \"left\", on=['index', 'library']).set_index('names')\n",
    "\n",
    "demux_adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbe34c0",
   "metadata": {},
   "source": [
    "## Load non-demux data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a175431",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_demux_meta = cells_meta.loc[~cells_meta['index'].isin(demux_meta['index'])]\n",
    "\n",
    "non_demux_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any library is missing cellbender paths\n",
    "cells_meta.path_cellbender_gex.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb632917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many samples per study\n",
    "non_demux_meta.study.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e5d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "adata = cellbender_to_anndata(non_demux_meta)\n",
    "\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10340d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata['A16_TH_TOT_1-AAACCTGTCGAGAGCA', 'TCF7'].X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.study.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a3cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = adata.var.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.concat([adata, demux_adata], merge = 'same', index_unique = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b17df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata['A16_TH_TOT_1-AAACCTGTCGAGAGCA', 'TCF7'].X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961d5be-277f-4509-857a-e2626f3c0e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.groupby(['chemistry_simple', 'type', 'study']).agg(n_donors = ('donor', 'nunique'),\n",
    "                                                             n_cells = ('age', 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b4dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.groupby(['study']).agg(n_donors = ('donor', 'nunique'),\n",
    "                                                             n_cells = ('age', 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.groupby(['study', 'age_group'], observed = True).agg(n_donors = ('donor', 'nunique'),\n",
    "                                                             n_cells = ('age', 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.groupby(['study', 'sort'], observed = True).agg(n_donors = ('donor', 'nunique'),\n",
    "                                                             n_cells = ('age', 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5plugin\n",
    "\n",
    "object_version = f'v3_{today}'\n",
    "\n",
    "# Convert columns of type object\n",
    "for col in adata.obs.columns:\n",
    "    if adata.obs[col].dtypes == 'object':\n",
    "        if isinstance(adata.obs[col].iloc[0], (bool)):\n",
    "            adata.obs[col] = adata.obs[col].astype(bool)\n",
    "        else:\n",
    "            adata.obs[col] = adata.obs[col].astype(str)\n",
    "\n",
    "adata.write_h5ad(\n",
    "            f'{general_data_path}/objects/rna/thyAgeing_all_unfiltered_{object_version}.zarr',\n",
    "            compression=hdf5plugin.FILTERS[\"zstd\"],\n",
    "            compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c0eb3",
   "metadata": {},
   "source": [
    "## QC & filtering\n",
    "\n",
    "### Mito, gene and read counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e74b954-3317-46dd-858f-13f0475a542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty cells\n",
    "print('Removing {} empty cells'.format(sum(adata.X.sum(1) == 0)[0,0]))\n",
    "print('Removing {} non-expressed genes'.format(sum(adata.X.sum(0) == 0)[0,0]))\n",
    "\n",
    "adata = adata[(adata.X.sum(1) > 0), (adata.X.sum(0) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3886d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metadata\n",
    "add_cell_metadata(adata, velocyto = False, cellbender = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b78d6b-30f8-4471-9ce7-c57dcd61110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito','percent_ribo', 'percent_hb'],\n",
    "             jitter=0.1, multi_panel=True, size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd8d486-08c0-49c7-bde1-f296ccaa7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.obs['n_counts'], range = (0, 1000), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ec156-4d92-448f-af25-ad42a5b7fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.obs['n_genes'], range = (0, 1000), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3c937-3615-48ac-b5ea-5063b2749e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[['n_genes','n_counts','percent_mito', 'percent_ribo', 'percent_hb']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f43afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata['A16_TH_TOT_1-AAACCTGTCGAGAGCA', 'TCF7'].X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.groupby('study')[['n_genes', 'n_counts', 'percent_mito', 'percent_ribo', 'percent_hb']].describe().to_csv(f'{data_path}/analysis/preprocessing/qc_summary_stats_by_study.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1fb051-0f6e-45b0-9cce-0a468c9a3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter raw cells according to identified QC thresholds:\n",
    "print('Total number of cells: {:d}'.format(adata.n_obs))\n",
    "\n",
    "sc.pp.filter_cells(adata, min_counts = 300)\n",
    "print('Number of cells after min count filter: {:d}'.format(adata.n_obs))\n",
    "\n",
    "sc.pp.filter_cells(adata, min_genes = 400)\n",
    "print('Number of cells after min genes filter: {:d}'.format(adata.n_obs))\n",
    "\n",
    "sc.pp.filter_cells(adata, max_genes = 10000)\n",
    "print('Number of cells after max genes filter: {:d}'.format(adata.n_obs))\n",
    "\n",
    "adata = adata[adata.obs['percent_mito'] < 0.15]\n",
    "print('Number of cells after mito filter: {:d}'.format(adata.n_obs))\n",
    "\n",
    "adata = adata[adata.obs['percent_ribo'] > 0.05]\n",
    "print('Number of cells after ribo filter: {:d}'.format(adata.n_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e221999-d9e9-414d-b81b-f210dd48cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns of type object\n",
    "for col in adata.obs.columns:\n",
    "    if adata.obs[col].dtypes == 'object':\n",
    "        if isinstance(adata.obs[col].iloc[0], (bool)):\n",
    "            adata.obs[col] = adata.obs[col].astype(bool)\n",
    "        else:\n",
    "            adata.obs[col] = adata.obs[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b7581-5277-414d-af79-a6942d997754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5plugin\n",
    "\n",
    "object_version = f'v3_{today}'\n",
    "\n",
    "adata.write_h5ad(\n",
    "            f'{general_data_path}/objects/rna/thyAgeing_all_filtered_{object_version}.zarr',\n",
    "            compression=hdf5plugin.FILTERS[\"zstd\"],\n",
    "            compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b431b3-fe31-433f-aef8-0bcc30e95c54",
   "metadata": {},
   "source": [
    "### Doublet removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246c474-22da-4a4b-bf57-179ae17742ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrublet as scr\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def doublet_detection(sample_object, sample_col='sample', n_cpu=4):\n",
    "    sc.settings.verbosity = 1  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "    scrdf = pd.DataFrame()\n",
    "    def process_sample(s):\n",
    "        # Import data\n",
    "        print('Doublet detection for sample {}'.format(s))\n",
    "        adata_sample = sample_object[sample_object.obs[sample_col] == s, :].copy()\n",
    "        if adata_sample.shape[0] > 100:\n",
    "            # Set up and run Scrublet\n",
    "            scrub = scr.Scrublet(adata_sample.X)\n",
    "            doublet_scores, predicted_doublets = scrub.scrub_doublets(verbose=False)\n",
    "            adata_sample.obs['scrublet_score'] = doublet_scores  # 1 scrublet score\n",
    "            adata_sample.obs['predicted_doublet'] = predicted_doublets\n",
    "            return adata_sample.obs[['scrublet_score', 'predicted_doublet']]\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=n_cpu) as executor:\n",
    "        results = list(executor.map(process_sample, sample_object.obs[sample_col].unique()))\n",
    "\n",
    "    scrdf = pd.concat(results)\n",
    "    return scrdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any sample with less than 100 cells\n",
    "samples_to_remove = adata.obs['sample'].value_counts().sort_values(ascending=True).to_frame(name='n_cells').reset_index(names='sample').query('n_cells < 100')['sample']\n",
    "\n",
    "adata = adata[~adata.obs['sample'].isin(samples_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019892a-66a7-478f-b7f0-9334a15f9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "doublet_scores = doublet_detection(adata, sample_col = 'sample', n_cpu = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb3b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "doublet_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15556d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doublet_scores.to_csv(f'{data_path}/analysis/preprocessing/thyAgeing_all_filtered_{object_version}_doubletScores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates barcodes (mostly from Notarangelo2024 multiplexed samples)\n",
    "doublet_scores.index.duplicated().sum() == adata.obs_names.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699efb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_barcodes = adata.obs[adata.obs_names.duplicated()].index\n",
    "\n",
    "adata[adata.obs_names.isin(dup_barcodes)].obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated barcodes from adata and scrublet_scores\n",
    "adata = adata[~adata.obs_names.duplicated()]\n",
    "scrublet_scores = doublet_scores[~doublet_scores.index.duplicated()]\n",
    "\n",
    "adata.shape[0] == scrublet_scores.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scrublet scores to adata\n",
    "adata.obs = adata.obs.join(scrublet_scores, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata['A16_TH_TOT_1-AAACCTGTCGAGAGCA', 'TCF7'].X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07864faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['predicted_doublet'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(adata.obs['scrublet_score'] < .3).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50210ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect doublet scores by sample\n",
    "adata.obs.groupby('sample')['predicted_doublet'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed35aaf-c4e8-446e-afe4-ed2f33c6a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove cells predicted to be doublets\n",
    "adata = adata[adata.obs['predicted_doublet'] != True,:]\n",
    "print('Number of cells after doublet filter: {:d}'.format(adata.n_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata['A16_TH_TOT_1-AAACCTGTCGAGAGCA', 'TCF7'].X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5plugin\n",
    "\n",
    "object_version = 'v3_2024-11-04'\n",
    "\n",
    "# Convert columns of type object\n",
    "for col in adata.obs.columns:\n",
    "    if adata.obs[col].dtypes == 'object':\n",
    "        if isinstance(adata.obs[col].iloc[0], (bool)):\n",
    "            adata.obs[col] = adata.obs[col].astype(bool)\n",
    "        else:\n",
    "            adata.obs[col] = adata.obs[col].astype(str)\n",
    "\n",
    "adata.write_h5ad(\n",
    "            f'{general_data_path}/objects/rna/thyAgeing_all_filtered_{object_version}.zarr',\n",
    "            compression=hdf5plugin.FILTERS[\"zstd\"],\n",
    "            compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e5dfa-2226-477e-bd35-017c17513111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
